{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from os import makedirs, path\n",
    "from copy import deepcopy\n",
    "from requests import request\n",
    "from pprint import pprint\n",
    "from bs4 import BeautifulSoup\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(input_string, mode = None):\n",
    "    \"\"\"\n",
    "    Utility function to clean the input string.\n",
    "    The filters are chosen by hand when scraping the values.\n",
    "    NOTE: Only add filters, don't remove them\n",
    "\n",
    "    :param input_string: String to be cleaned\n",
    "    :param mode: Useful to avoid adding spaces in case of select fields\n",
    "    :return: Cleaned string\n",
    "    \"\"\"\n",
    "    return input_string.strip().replace(u\"\\xa0â€‹\", \"\").replace(u\"â€‹\", \"\").replace(u\"\\n\", \"\").replace(u\"\\t\", \"\").replace(u\"\\xa0\", \" \" if (mode and mode == 'prof') else \"\").replace(u\"\\u200b\", \"\").replace(u\"\\u00e0\", \"à\")\n",
    "\n",
    "\n",
    "def initialize_dataset():\n",
    "    \"\"\"\n",
    "    Return an object to use for inizialization of a new dataset.\n",
    "\n",
    "    :return: Initial dictionary for any dataset\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"value\": {\n",
    "            \"total\": 0,\n",
    "            \"size\": 0,\n",
    "            \"language\": \"en\",\n",
    "            \"data\": []\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "def append_data(dataset, to_append):\n",
    "    \"\"\"\n",
    "    Utility function to mask away some code and make it more readable\n",
    "\n",
    "    :param dataset: Dataset to append data to\n",
    "    :param to_append: Data to append\n",
    "    \"\"\"\n",
    "    dataset['value']['data'].append(to_append)\n",
    "\n",
    "\n",
    "def save_dataset(dataset, name, file_format):\n",
    "    \"\"\"\n",
    "    Save the dataset given in input\n",
    "\n",
    "    :param dataset: Dataset to save\n",
    "    :param name: Name of the dataset\n",
    "    :param file_format: Format the dataset should be saved in\n",
    "    \"\"\"\n",
    "    filename = f'../datasets/{name}.{file_format}'\n",
    "    makedirs(path.dirname(filename), exist_ok=True)\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        if file_format == 'json':\n",
    "            json.dump(dataset, f, indent=2)\n",
    "\n",
    "\n",
    "def set_total_size(dataset):\n",
    "    \"\"\"\n",
    "    Sets the values of the 'total' and 'size' fields in a dictionary\n",
    "\n",
    "    :param dataset: Dataset to manipulate\n",
    "    \"\"\"\n",
    "    dataset['value']['total'] = len(dataset['value']['data'])\n",
    "    dataset['value']['size'] = len(dataset['value']['data'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'credits': '6',\n",
      " 'evaluationType': 'Voto Finale',\n",
      " 'examType': 'Orale',\n",
      " 'id': 'f3e4f074990545bb83f89e0b4d6c841d',\n",
      " 'lessonPeriod': 'Primo Semestre',\n",
      " 'lessonType': 'Lezioni',\n",
      " 'typeCourse': 'Caratterizzante',\n",
      " 'year': '1&2'}\n"
     ]
    }
   ],
   "source": [
    "def scrape_esse3(url):\n",
    "    \"\"\"\n",
    "    Scrape the given URL and extract all the needed information\n",
    "\n",
    "    :param url: Url to scrape\n",
    "    :return: Dictionary of information for the given URL\n",
    "    \"\"\"\n",
    "    # Uncomment the following and comment lines [99-101] to download the page instead of using the local one\n",
    "    res = request('get', url, headers={\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; rv:106.0) Gecko/20100101 Firefox/106.0', \"Accept-Language\": \"en-US,en;q=0.5\"})\n",
    "    # with open('prova.html', 'w', encoding='utf-8') as f:\n",
    "    #     f.write(res.text)\n",
    "    if res.ok:\n",
    "        soup = BeautifulSoup(res.text, 'lxml')\n",
    "        # with open('prova3.html', \"r\") as f:\n",
    "        #     page = f.read()\n",
    "        # soup = BeautifulSoup(page, 'lxml')\n",
    "        course_id = uuid.uuid4().hex\n",
    "        if soup.find(id='header2').find('h2').string == \"Errore\":\n",
    "            information = {\n",
    "                'id': course_id,\n",
    "                'year': 'NA',\n",
    "                'typeCourse': 'NA',\n",
    "                'credits': 'NA',\n",
    "                'lessonType': 'NA',\n",
    "                'examType': 'NA',\n",
    "                'evaluationType': 'NA',\n",
    "                'lessonPeriod': 'NA'\n",
    "            }\n",
    "        else:\n",
    "            table_values = soup.find_all('dd')\n",
    "            teaching_units_html = soup.find(\n",
    "                id=\"table1\").find('tbody').find_all(\"tr\")\n",
    "            teaching_units = []\n",
    "            for i in range(len(teaching_units_html)):\n",
    "                unit = teaching_units_html[i].find_all(\"td\")\n",
    "                unitId = uuid.uuid4().hex\n",
    "                if len(unit) < 6:\n",
    "                    # Probably an error in the input, see https://www.esse3.unitn.it/Guide/PaginaADContest.do?ad_cont_id=10661*94459*2022*2017*9999\n",
    "                    previous_unit = teaching_units_html[i-1].find_all(\"td\")\n",
    "                    unit_information = {\n",
    "                        'courseId': course_id,\n",
    "                        'name': clean_string(previous_unit[0].string),\n",
    "                        'activityType': clean_string(unit[0].string) if unit[0].string else '',\n",
    "                        'durationHours': clean_string(unit[1].string) if unit[1].string else '',\n",
    "                        'typeTeaching': clean_string(unit[2].string) if unit[2].string else '',\n",
    "                        'subjectArea': clean_string(unit[3].string) if unit[3].string else '',\n",
    "                        'credits': clean_string(unit[4].string) if unit[4].string else '',\n",
    "                        'id': unitId\n",
    "                    }\n",
    "                else:\n",
    "                    unit_information = {\n",
    "                        'courseId': course_id,\n",
    "                        'name': clean_string(unit[0].string),\n",
    "                        'activityType': clean_string(unit[1].string) if unit[1].string else '',\n",
    "                        'durationHours': clean_string(unit[2].string) if unit[2].string else '',\n",
    "                        'typeTeaching': clean_string(unit[3].string) if unit[3].string else '',\n",
    "                        'subjectArea': clean_string(unit[4].string) if unit[4].string else '',\n",
    "                        'credits': clean_string(unit[5].string) if unit[5].string else '',\n",
    "                        'id': unitId\n",
    "                    }\n",
    "                teaching_units.append(unit_information)\n",
    "\n",
    "            partitions_html = soup.find(id=\"table2\").find(\n",
    "                'tbody').find_all(\"tr\") if soup.find(id=\"table2\") else None\n",
    "            partitions = []\n",
    "            last_rowspan = {\n",
    "                'partition': 1,\n",
    "                'syllabus': 1\n",
    "            }\n",
    "            append_new = True\n",
    "            professor = {\n",
    "                'count': 0,\n",
    "                'name': '',\n",
    "                'tenured': True\n",
    "            }\n",
    "            if partitions_html:\n",
    "                for i in range(len(partitions_html)):\n",
    "                    partition = partitions_html[i].find_all(\"td\")\n",
    "                    partitionId = uuid.uuid4().hex\n",
    "                    if list(last_rowspan.values()) == [1, 1]:\n",
    "                        partition_information = {\n",
    "                            'name': clean_string(partition[0].string),\n",
    "                            'period': clean_string(partition[1].string),\n",
    "                            'teacher': {'name': [clean_string(partition[2].string, 'prof') if partition[2].string else ''], 'tenured': [True if partition[3].find('img') else False]},\n",
    "                            'syllabusLink': 'https://www.esse3.unitn.it/'+partition[4].find('a')['href'] if partition[4].find('a') else '' if partition[4] else '',\n",
    "                        }\n",
    "                        last_rowspan = {\n",
    "                            'partition': int(partition[0]['rowspan']),\n",
    "                            'syllabus': int(partition[4]['rowspan'])\n",
    "                        }\n",
    "                        if partition[2].string and clean_string(partition[2].string, 'prof') != '':\n",
    "                            professor['count'] += 1\n",
    "                            professor['name'] = clean_string(\n",
    "                                partition[2].string, 'prof')\n",
    "                            professor['tenured'] = True if partition[3].find(\n",
    "                                'img') else False\n",
    "                    else:\n",
    "                        if last_rowspan['partition'] <= 1:\n",
    "                            partition_information = {\n",
    "                                'name': clean_string(partition[0].string),\n",
    "                                'period': clean_string(partition[1].string),\n",
    "                                'teacher': {'name': [clean_string(partition[2].string, 'prof') if partition[2].string else ''], 'tenured': [True if partition[3].find('img') else False]},\n",
    "                                'syllabusLink': '',\n",
    "                            }\n",
    "                            append_new = True\n",
    "                            if partition[2].string and clean_string(partition[2].string) != '':\n",
    "                                professor['count'] += 1\n",
    "                                professor['name'] = clean_string(\n",
    "                                    partition[2].string, 'prof')\n",
    "                                professor['tenured'] = True if partition[3].find(\n",
    "                                    'img') else False\n",
    "                        else:\n",
    "                            last_rowspan['partition'] -= 1\n",
    "                            partitions[-1]['teacher']['name'].append(clean_string(\n",
    "                                partition[0].string, 'prof') if partition[0].string else '')\n",
    "                            partitions[-1]['teacher']['tenured'].append(\n",
    "                                True if partition[1].find('img') else False)\n",
    "                            append_new = False\n",
    "                            if partition[0].string and clean_string(partition[0].string) != '':\n",
    "                                professor['count'] += 1\n",
    "                                professor['name'] = clean_string(\n",
    "                                    partition[0].string, 'prof')\n",
    "                                professor['tenured'] = True if partition[1].find(\n",
    "                                    'img') else False\n",
    "\n",
    "                        if last_rowspan['syllabus'] <= 1:\n",
    "                            partition_information['syllabusLink'] = clean_string(partition[4].string) if len(\n",
    "                                partition) >= 5 and partition[4] else partition_information['syllabusLink']\n",
    "                        else:\n",
    "                            last_rowspan['syllabus'] -= 1\n",
    "                            if partitions[-1]['syllabusLink'] == '':\n",
    "                                partitions[-1]['syllabusLink'] = clean_string(partition[2].string) if len(\n",
    "                                    partition) >= 3 and partition[2] else partition_information['syllabusLink']\n",
    "                    if append_new:\n",
    "                        partition_information['courseId'] = course_id\n",
    "                        partition_information['id'] = partitionId\n",
    "                        partitions.append(partition_information)\n",
    "                if professor['count'] == 1:\n",
    "                    for partition in partitions:\n",
    "                        partition['teacher']['name'] = [professor['name']]\n",
    "                        partition['teacher']['tenured'] = [\n",
    "                            professor['tenured']]\n",
    "\n",
    "            course_year = '0'\n",
    "            year_tmp = table_values[0].contents[0].string.split(',')\n",
    "            if len(year_tmp) > 1:\n",
    "                course_year = year_tmp[0][0] + '&' + year_tmp[1][1]\n",
    "            elif table_values[0].contents[0].string[0] in {'1', '2', '3', '4', '5'}:\n",
    "                course_year = table_values[0].contents[0].string[0]\n",
    "            else:\n",
    "                course_year = clean_string(table_values[0].contents[0].string)\n",
    "            information = {\n",
    "                'id': course_id,\n",
    "                'year': course_year,\n",
    "                'typeCourse': clean_string(table_values[1].contents[0]),\n",
    "                'credits': clean_string(table_values[2].contents[0].string.split(\" \")[0]),\n",
    "                'lessonType': clean_string(soup.find(\"desc_tipo_att\").contents[0].string if soup.find(\"desc_tipo_att\") else ''),\n",
    "                'examType': clean_string(table_values[4].contents[0].string),\n",
    "                'evaluationType': clean_string(table_values[5].contents[0].string),\n",
    "                'lessonPeriod': clean_string(table_values[6].contents[0].string)\n",
    "            }\n",
    "    else:\n",
    "        # add better error control with an exception\n",
    "        print(f\"Cannot download the page from {url}.\")\n",
    "        return {}, [], []\n",
    "\n",
    "    \"\"\" with open('prova_esse3.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(information, f) \"\"\"\n",
    "    # pprint(information)\n",
    "    return information, partitions, teaching_units\n",
    "\n",
    "\n",
    "information, partitions, teaching_units = scrape_esse3(\n",
    "    'https://www.esse3.unitn.it/Guide/PaginaADContest.do?ad_cont_id=10117*87830*2022*2011*10000&cod_lingua=en')\n",
    "pprint(information)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d11d5ba9fe4446fc540f97500dc098ff60833f4cf89c243c63a6d1251da9f9dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
